{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30823,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install py7zr evaluate rouge_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:54:32.968926Z","iopub.execute_input":"2025-01-01T17:54:32.969215Z","iopub.status.idle":"2025-01-01T17:54:41.222533Z","shell.execute_reply.started":"2025-01-01T17:54:32.969192Z","shell.execute_reply":"2025-01-01T17:54:41.221498Z"}},"outputs":[{"name":"stdout","text":"Collecting py7zr\n  Downloading py7zr-0.22.0-py3-none-any.whl.metadata (16 kB)\nCollecting evaluate\n  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\nCollecting rouge_score\n  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: texttable in /usr/local/lib/python3.10/dist-packages (from py7zr) (1.7.0)\nRequirement already satisfied: pycryptodomex>=3.16.0 in /usr/local/lib/python3.10/dist-packages (from py7zr) (3.21.0)\nCollecting pyzstd>=0.15.9 (from py7zr)\n  Downloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\nCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr)\n  Downloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.5 kB)\nCollecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n  Downloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.9 kB)\nCollecting multivolumefile>=0.2.3 (from py7zr)\n  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\nCollecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n  Downloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.8 kB)\nCollecting brotli>=1.1.0 (from py7zr)\n  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (5.5 kB)\nRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from py7zr) (5.9.5)\nRequirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\nRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\nRequirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\nRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\nRequirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.5)\nRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\nRequirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.6.1)\nRequirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.24.7)\nRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.1)\nRequirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.4.0)\nRequirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge_score) (3.2.4)\nRequirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from rouge_score) (1.16.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\nRequirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\nRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.10.5)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\nRequirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.1)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\nRequirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.11.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\nDownloading py7zr-0.22.0-py3-none-any.whl (67 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.9/67.9 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m42.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading inflate64-1.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.3/93.3 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\nDownloading pybcj-1.0.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.6/49.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyppmd-1.1.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.0/139.0 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pyzstd-0.16.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.7/413.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hBuilding wheels for collected packages: rouge_score\n  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24935 sha256=8605f906f85a9f2c958295084ed6371bc4a148d97651e0cf81c500f60fe230a3\n  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\nSuccessfully built rouge_score\nInstalling collected packages: brotli, pyzstd, pyppmd, pybcj, multivolumefile, inflate64, rouge_score, py7zr, evaluate\nSuccessfully installed brotli-1.1.0 evaluate-0.4.3 inflate64-1.0.1 multivolumefile-0.2.3 py7zr-0.22.0 pybcj-1.0.3 pyppmd-1.1.1 pyzstd-0.16.2 rouge_score-0.1.2\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import torch\nimport evaluate\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, AutoModelForSeq2SeqLM\nfrom torch.utils.data import DataLoader\nfrom transformers import DataCollatorForSeq2Seq\nfrom tqdm import tqdm\nfrom transformers import get_linear_schedule_with_warmup","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:54:41.223660Z","iopub.execute_input":"2025-01-01T17:54:41.223885Z","iopub.status.idle":"2025-01-01T17:54:54.738811Z","shell.execute_reply.started":"2025-01-01T17:54:41.223866Z","shell.execute_reply":"2025-01-01T17:54:54.738138Z"}},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":"## Data Loading","metadata":{}},{"cell_type":"code","source":"dataset = load_dataset(\"allenai/scitldr\", trust_remote_code=True)\ndataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:54:54.740105Z","iopub.execute_input":"2025-01-01T17:54:54.740676Z","iopub.status.idle":"2025-01-01T17:55:00.538322Z","shell.execute_reply.started":"2025-01-01T17:54:54.740650Z","shell.execute_reply":"2025-01-01T17:55:00.537492Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/8.81k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb45d698f747416ea910643cc9d2941f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"scitldr.py:   0%|          | 0.00/7.21k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6256948567e4b75865da6d7cae73c71"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"dataset_infos.json:   0%|          | 0.00/7.56k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"47ba6fe7736446229a288094df8f6845"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/3.16M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d21523cfe21466fa88da8374850fd39"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.12M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26f3a437ffaa4d67876bc95a3547c130"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/1.20M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1d065e88b0ba4df5808058229040a430"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/1992 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"991056c163d84625a5d3a1629ab36fd1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/618 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"44bd6233c34a4ca3bc280e98ea64ac45"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/619 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7683f97edac34194b4a00ca991978532"}},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n        num_rows: 1992\n    })\n    test: Dataset({\n        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n        num_rows: 618\n    })\n    validation: Dataset({\n        features: ['source', 'source_labels', 'rouge_scores', 'paper_id', 'target'],\n        num_rows: 619\n    })\n})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"dataset['train'][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:00.539456Z","iopub.execute_input":"2025-01-01T17:55:00.539695Z","iopub.status.idle":"2025-01-01T17:55:00.547120Z","shell.execute_reply.started":"2025-01-01T17:55:00.539675Z","shell.execute_reply":"2025-01-01T17:55:00.546511Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"{'source': ['Due to the success of deep learning to solving a variety of challenging machine learning tasks, there is a rising interest in understanding loss functions for training neural networks from a theoretical aspect.',\n  'Particularly, the properties of critical points and the landscape around them are of importance to determine the convergence performance of optimization algorithms.',\n  'In this paper, we provide a necessary and sufficient characterization of the analytical forms for the critical points (as well as global minimizers) of the square loss functions for linear neural networks.',\n  'We show that the analytical forms of the critical points characterize the values of the corresponding loss functions as well as the necessary and sufficient conditions to achieve global minimum.',\n  'Furthermore, we exploit the analytical forms of the critical points to characterize the landscape properties for the loss functions of linear neural networks and shallow ReLU networks.',\n  'One particular conclusion is that: While the loss function of linear networks has no spurious local minimum, the loss function of one-hidden-layer nonlinear networks with ReLU activation function does have local minimum that is not global minimum.'],\n 'source_labels': [0, 0, 0, 0, 1, 0],\n 'rouge_scores': [0.30188679695129395,\n  0.3720930218696594,\n  0.6037735939025879,\n  0.5714285373687744,\n  0.7234042286872864,\n  0.15094339847564697],\n 'paper_id': 'SysEexbRb',\n 'target': ['We provide necessary and sufficient analytical forms for the critical points of the square loss functions for various neural networks, and exploit the analytical forms to characterize the landscape properties for the loss functions of these neural networks.']}"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## Model Loading","metadata":{}},{"cell_type":"code","source":"device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:00.547947Z","iopub.execute_input":"2025-01-01T17:55:00.548228Z","iopub.status.idle":"2025-01-01T17:55:00.612833Z","shell.execute_reply.started":"2025-01-01T17:55:00.548199Z","shell.execute_reply":"2025-01-01T17:55:00.612018Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model_name = \"google/pegasus-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForSeq2SeqLM.from_pretrained(model_name).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:00.613585Z","iopub.execute_input":"2025-01-01T17:55:00.613788Z","iopub.status.idle":"2025-01-01T17:55:22.691689Z","shell.execute_reply.started":"2025-01-01T17:55:00.613770Z","shell.execute_reply":"2025-01-01T17:55:22.690774Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/88.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6956ac00fe5944efb3758f6a055b4baf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/3.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b503bdfddbf54356a4b6bc9514056bb6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"spiece.model:   0%|          | 0.00/1.91M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d88d6b21da95475687fba055ba54f1df"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/65.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fefc7687c7ac42bba95594b975f28e51"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/2.28G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf0dc9cbf3741f49ad63072bb9a3d05"}},"metadata":{}},{"name":"stderr","text":"Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-large and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/260 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3ffbaa32bc2943b883889da888693f63"}},"metadata":{}}],"execution_count":6},{"cell_type":"code","source":"for param in model.parameters():\n    param.requires_grad = False\n\nfor layer in model.model.encoder.layers[-2:]:\n    for param in layer.parameters():\n        param.requires_grad = True\n        \nfor layer in model.model.decoder.layers[-2:]:\n    for param in layer.parameters():\n        param.requires_grad = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.692485Z","iopub.execute_input":"2025-01-01T17:55:22.692721Z","iopub.status.idle":"2025-01-01T17:55:22.699715Z","shell.execute_reply.started":"2025-01-01T17:55:22.692701Z","shell.execute_reply":"2025-01-01T17:55:22.698819Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"# for name, param in model.named_parameters():\n#     print(f\"{name}: {'Trainable' if param.requires_grad else 'Frozen'}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.701948Z","iopub.execute_input":"2025-01-01T17:55:22.702174Z","iopub.status.idle":"2025-01-01T17:55:22.714008Z","shell.execute_reply.started":"2025-01-01T17:55:22.702156Z","shell.execute_reply":"2025-01-01T17:55:22.713065Z"}},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":"## Data Preprocessing","metadata":{}},{"cell_type":"code","source":"class ScientificDataset(torch.utils.data.Dataset):\n    def __init__(self, dataset, tokenizer, max_source_length=512, max_target_length=128):\n        self.dataset = dataset\n        self.tokenizer = tokenizer\n        self.max_source_length = max_source_length\n        self.max_target_length = max_target_length\n\n    def __len__(self):\n        return len(self.dataset)\n\n    def __getitem__(self, idx):\n        item = self.dataset[idx]\n        source_text = ' '.join(item['source'])  # Join source sentences\n        target_text = item['target'][0]  # Take first target summary\n\n        # Tokenize source\n        source_encoding = self.tokenizer(\n            source_text,\n            max_length=self.max_source_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        # Tokenize target\n        target_encoding = self.tokenizer(\n            target_text,\n            max_length=self.max_target_length,\n            padding='max_length',\n            truncation=True,\n            return_tensors='pt'\n        )\n\n        return {\n            'input_ids': source_encoding['input_ids'].squeeze(),\n            'attention_mask': source_encoding['attention_mask'].squeeze(),\n            'labels': target_encoding['input_ids'].squeeze()\n        }","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.715158Z","iopub.execute_input":"2025-01-01T17:55:22.715400Z","iopub.status.idle":"2025-01-01T17:55:22.728022Z","shell.execute_reply.started":"2025-01-01T17:55:22.715380Z","shell.execute_reply":"2025-01-01T17:55:22.727236Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"train_dataset = ScientificDataset(dataset['train'], tokenizer)\nval_dataset = ScientificDataset(dataset['validation'], tokenizer)\ntest_dataset = ScientificDataset(dataset['test'], tokenizer)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.728891Z","iopub.execute_input":"2025-01-01T17:55:22.729178Z","iopub.status.idle":"2025-01-01T17:55:22.745135Z","shell.execute_reply.started":"2025-01-01T17:55:22.729151Z","shell.execute_reply":"2025-01-01T17:55:22.744340Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"batch_size = 4\ntrain_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=batch_size)\ntest_loader = DataLoader(test_dataset, batch_size=batch_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.745952Z","iopub.execute_input":"2025-01-01T17:55:22.746238Z","iopub.status.idle":"2025-01-01T17:55:22.759969Z","shell.execute_reply.started":"2025-01-01T17:55:22.746213Z","shell.execute_reply":"2025-01-01T17:55:22.759115Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"metric = evaluate.load(\"rouge\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:22.760812Z","iopub.execute_input":"2025-01-01T17:55:22.761068Z","iopub.status.idle":"2025-01-01T17:55:24.964139Z","shell.execute_reply.started":"2025-01-01T17:55:22.761036Z","shell.execute_reply":"2025-01-01T17:55:24.963130Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.27k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"20f1651ae9a94981b3cde2073748e0f8"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def compute_metrics(predictions, labels):\n    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n    result = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n    return result","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:24.965291Z","iopub.execute_input":"2025-01-01T17:55:24.965642Z","iopub.status.idle":"2025-01-01T17:55:24.971211Z","shell.execute_reply.started":"2025-01-01T17:55:24.965610Z","shell.execute_reply":"2025-01-01T17:55:24.970336Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=5e-5)\nnum_epochs = 5\nnum_training_steps = len(train_loader) * num_epochs\nscheduler = get_linear_schedule_with_warmup(\n    optimizer,\n    num_warmup_steps=num_training_steps // 10,\n    num_training_steps=num_training_steps\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:24.972014Z","iopub.execute_input":"2025-01-01T17:55:24.972382Z","iopub.status.idle":"2025-01-01T17:55:28.708318Z","shell.execute_reply.started":"2025-01-01T17:55:24.972348Z","shell.execute_reply":"2025-01-01T17:55:28.707163Z"}},"outputs":[],"execution_count":14},{"cell_type":"markdown","source":"## Model Training","metadata":{}},{"cell_type":"code","source":"# Faster Loop (without generating predictions)\n\nfor epoch in range(num_epochs):\n    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n    epoch_loss = 0\n    model.train()\n    for batch in tqdm(train_loader):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        optimizer.zero_grad()\n        outputs = model(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            labels=labels\n        )\n        loss = outputs.loss\n        loss.backward()\n        optimizer.step()\n\n        epoch_loss += loss.item()\n\n    avg_loss = epoch_loss / len(train_loader)\n    print(f\"Average training loss: {avg_loss}\")\n\n    model.eval()\n    val_loss = 0\n    for batch in tqdm(val_loader):\n        input_ids = batch[\"input_ids\"].to(device)\n        attention_mask = batch[\"attention_mask\"].to(device)\n        labels = batch[\"labels\"].to(device)\n\n        with torch.no_grad():\n            outputs = model(\n                input_ids=input_ids,\n                attention_mask=attention_mask,\n                labels=labels\n            )\n            loss = outputs.loss\n            val_loss += loss.item()\n\n    avg_val_loss = val_loss / len(val_loader)\n    print(f\"Average validation loss: {avg_val_loss}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T17:55:28.709198Z","iopub.execute_input":"2025-01-01T17:55:28.709477Z","iopub.status.idle":"2025-01-01T18:16:11.568205Z","shell.execute_reply.started":"2025-01-01T17:55:28.709457Z","shell.execute_reply":"2025-01-01T18:16:11.567381Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 498/498 [03:29<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 12.355617685969095\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 155/155 [00:39<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average validation loss: 13.080345301474294\nEpoch 2/5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 498/498 [03:28<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 12.368804357138025\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 155/155 [00:39<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average validation loss: 13.080345301474294\nEpoch 3/5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 498/498 [03:28<00:00,  2.39it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 12.38977995072024\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 155/155 [00:39<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average validation loss: 13.080345301474294\nEpoch 4/5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 498/498 [03:28<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 12.371697827994105\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 155/155 [00:39<00:00,  3.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average validation loss: 13.080345301474294\nEpoch 5/5\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 498/498 [03:28<00:00,  2.38it/s]\n","output_type":"stream"},{"name":"stdout","text":"Average training loss: 12.355947113420111\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 155/155 [00:39<00:00,  3.93it/s]","output_type":"stream"},{"name":"stdout","text":"Average validation loss: 13.080345301474294\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"# # Slower Loop (generate predictions and calculate the rouge metric)\n\n# calc_interval = 4  # Generate predictions every 4 batches (you can increase it to speed the loop up, but it will need more memory)\n# print_interval = 128  # Print ROUGE metrics every 128 batches\n\n# for epoch in range(num_epochs):\n#     print(f\"Epoch {epoch + 1}/{num_epochs}\")\n#     epoch_loss = 0\n#     model.train()\n\n#     # Training: Initialize storage for accumulated inputs\n#     accumulated_input_ids = []\n#     accumulated_attention_masks = []\n#     accumulated_labels = []\n#     all_train_preds = []\n#     all_train_labels = []\n\n#     for batch_idx, batch in enumerate(tqdm(train_loader, desc=\"Training\")):\n#         input_ids = batch[\"input_ids\"].to(device)\n#         attention_mask = batch[\"attention_mask\"].to(device)\n#         labels = batch[\"labels\"].to(device)\n\n#         optimizer.zero_grad()\n#         outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n#         loss = outputs.loss\n#         loss.backward()\n#         optimizer.step()\n\n#         epoch_loss += loss.item()\n\n#         # Accumulate inputs and labels\n#         accumulated_input_ids.append(input_ids)\n#         accumulated_attention_masks.append(attention_mask)\n#         accumulated_labels.append(labels)\n\n#         # Generate predictions every `calc_interval` batches\n#         if (batch_idx + 1) % calc_interval == 0:\n#             with torch.no_grad():\n#                 input_ids = torch.cat(accumulated_input_ids, dim=0)\n#                 attention_mask = torch.cat(accumulated_attention_masks, dim=0)\n#                 labels = torch.cat(accumulated_labels, dim=0)\n\n#                 generated_ids = model.generate(\n#                     input_ids=input_ids,\n#                     attention_mask=attention_mask,\n#                     max_length=128,\n#                     num_beams=4,\n#                     early_stopping=True\n#                 )\n#                 decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n#                 decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n#                 all_train_preds.extend(decoded_preds)\n#                 all_train_labels.extend(decoded_labels)\n\n#             # Reset accumulated inputs\n#             accumulated_input_ids = []\n#             accumulated_attention_masks = []\n#             accumulated_labels = []\n\n#         # Print metrics every `print_interval` batches\n#         if (batch_idx + 1) % print_interval == 0:\n#             train_metrics = metric.compute(predictions=all_train_preds, references=all_train_labels, use_stemmer=True)\n#             print(f\"Train ROUGE after {batch_idx + 1} batches: {train_metrics}\")\n\n#     # Final metrics for remaining training batches\n#     if accumulated_input_ids:\n#         with torch.no_grad():\n#             input_ids = torch.cat(accumulated_input_ids, dim=0)\n#             attention_mask = torch.cat(accumulated_attention_masks, dim=0)\n#             labels = torch.cat(accumulated_labels, dim=0)\n\n#             generated_ids = model.generate(\n#                 input_ids=input_ids,\n#                 attention_mask=attention_mask,\n#                 max_length=128,\n#                 num_beams=4,\n#                 early_stopping=True\n#             )\n#             decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n#             decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n#             all_train_preds.extend(decoded_preds)\n#             all_train_labels.extend(decoded_labels)\n\n#             train_metrics = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n#             print(f\"Final Train ROUGE for remaining batches: {train_metrics}\")\n\n#     avg_loss = epoch_loss / len(train_loader)\n#     print(f\"Average training loss for epoch {epoch + 1}: {avg_loss}\")\n\n#     # Final epoch ROUGE for training\n#     epoch_train_metrics = metric.compute(predictions=all_train_preds, references=all_train_labels, use_stemmer=True)\n#     print(f\"Train ROUGE scores for epoch {epoch + 1}: {epoch_train_metrics}\")\n\n#     # Validation\n#     model.eval()\n#     val_loss = 0\n\n#     # Validation: Initialize storage for accumulated inputs\n#     accumulated_input_ids = []\n#     accumulated_attention_masks = []\n#     accumulated_labels = []\n#     all_val_preds = []\n#     all_val_labels = []\n\n#     with torch.no_grad():\n#         for batch_idx, batch in enumerate(tqdm(val_loader, desc=\"Validating\")):\n#             input_ids = batch[\"input_ids\"].to(device)\n#             attention_mask = batch[\"attention_mask\"].to(device)\n#             labels = batch[\"labels\"].to(device)\n\n#             outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n#             loss = outputs.loss\n#             val_loss += loss.item()\n\n#             # Accumulate inputs and labels\n#             accumulated_input_ids.append(input_ids)\n#             accumulated_attention_masks.append(attention_mask)\n#             accumulated_labels.append(labels)\n\n#             # Generate predictions every `calc_interval` batches\n#             if (batch_idx + 1) % calc_interval == 0:\n#                 input_ids = torch.cat(accumulated_input_ids, dim=0)\n#                 attention_mask = torch.cat(accumulated_attention_masks, dim=0)\n#                 labels = torch.cat(accumulated_labels, dim=0)\n\n#                 generated_ids = model.generate(\n#                     input_ids=input_ids,\n#                     attention_mask=attention_mask,\n#                     max_length=128,\n#                     num_beams=4,\n#                     early_stopping=True\n#                 )\n#                 decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n#                 decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n#                 all_val_preds.extend(decoded_preds)\n#                 all_val_labels.extend(decoded_labels)\n\n#                 # Reset accumulated inputs\n#                 accumulated_input_ids = []\n#                 accumulated_attention_masks = []\n#                 accumulated_labels = []\n\n#             # Print metrics every `print_interval` batches\n#             if (batch_idx + 1) % print_interval == 0:\n#                 val_metrics = metric.compute(predictions=all_val_preds, references=all_val_labels, use_stemmer=True)\n#                 print(f\"Validation ROUGE after {batch_idx + 1} batches: {val_metrics}\")\n\n#         # Final metrics for remaining validation batches\n#         if accumulated_input_ids:\n#             input_ids = torch.cat(accumulated_input_ids, dim=0)\n#             attention_mask = torch.cat(accumulated_attention_masks, dim=0)\n#             labels = torch.cat(accumulated_labels, dim=0)\n\n#             generated_ids = model.generate(\n#                 input_ids=input_ids,\n#                 attention_mask=attention_mask,\n#                 max_length=128,\n#                 num_beams=4,\n#                 early_stopping=True\n#             )\n#             decoded_preds = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)\n#             decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n\n#             all_val_preds.extend(decoded_preds)\n#             all_val_labels.extend(decoded_labels)\n\n#             val_metrics = metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n#             print(f\"Final Validation ROUGE for remaining batches: {val_metrics}\")\n\n#     avg_val_loss = val_loss / len(val_loader)\n#     print(f\"Average validation loss for epoch {epoch + 1}: {avg_val_loss}\")\n\n#     # Final epoch ROUGE for validation\n#     epoch_val_metrics = metric.compute(predictions=all_val_preds, references=all_val_labels, use_stemmer=True)\n#     print(f\"Validation ROUGE scores for epoch {epoch + 1}: {epoch_val_metrics}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T18:16:11.569010Z","iopub.execute_input":"2025-01-01T18:16:11.569313Z","iopub.status.idle":"2025-01-01T18:16:11.574292Z","shell.execute_reply.started":"2025-01-01T18:16:11.569273Z","shell.execute_reply":"2025-01-01T18:16:11.573522Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"## Model Evaluation","metadata":{}},{"cell_type":"code","source":"model.eval()\n\nall_test_preds = []\nall_test_labels = []\n\nwith torch.no_grad():\n    for batch in tqdm(test_loader, desc=\"Evaluating on Test Data\"):\n        input_ids = batch['input_ids'].to(device)\n        attention_mask = batch['attention_mask'].to(device)\n        labels = batch['labels'].to(device)\n\n        generated_ids = model.generate(\n            input_ids=input_ids,\n            attention_mask=attention_mask,\n            max_length=128,\n            num_beams=4,\n            early_stopping=True\n        )\n\n        all_test_preds.extend(generated_ids.cpu().numpy())\n        all_test_labels.extend(labels.cpu().numpy())\n\ntest_metrics = compute_metrics(all_test_preds, all_test_labels)\nprint(\"Test ROUGE scores:\", test_metrics)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-01T18:16:11.575046Z","iopub.execute_input":"2025-01-01T18:16:11.575311Z","iopub.status.idle":"2025-01-01T18:20:25.841580Z","shell.execute_reply.started":"2025-01-01T18:16:11.575279Z","shell.execute_reply":"2025-01-01T18:20:25.840740Z"}},"outputs":[{"name":"stderr","text":"Evaluating on Test Data: 100%|██████████| 155/155 [04:12<00:00,  1.63s/it]\n","output_type":"stream"},{"name":"stdout","text":"Test ROUGE scores: {'rouge1': 0.2818282501874282, 'rouge2': 0.09582032387882065, 'rougeL': 0.2114834523666631, 'rougeLsum': 0.21120538514214185}\n","output_type":"stream"}],"execution_count":17},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}